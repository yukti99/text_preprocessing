YUKTI KHURANA

PROBLEM STATEMENT: 
"
Write a program that preprocesses a collection of documents. You will test this
program on any of the standard dataset. You can also create your own collection of
documents and use it for testing.

The program should have following main functionalities:
1.Tokenization
2. Stopwords Removal
3. Normalization of text ( including noise removal)
4.Stemming/Lemmatization

Finally your program should display;
1.the total number of words in the collection
2.vocabulary size (i.e., number of unique terms)
3.most frequent 50 words in the collection, along with their frequencies (list in reverse
order of their frequency)
4.show stemmed/lemmatized version of any text segment
5.normalized version of any text segment
6.any other functionality included in the program

"

1. Code written in python3
2. documents - 1,2,3,4 are being used for preprocessing so they should remain in the same folder
3. driver.py will use the class NLP_TextPreprocessing.py

TO EXECUTE:
		python3 driver.py

OUTPUT:
		Output_TextProcessing.txt